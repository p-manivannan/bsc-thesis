{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82b0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=1     \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8eac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "from result_analysis_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfa4ddf",
   "metadata": {},
   "source": [
    "# Results Analysis\n",
    "\n",
    "Analyse results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d765c1",
   "metadata": {},
   "source": [
    "# Accuracy and average uncertainty:\n",
    "Data shape of preds and lockbox: (9, 50, 576, 4), 50 forward passes. \n",
    "\n",
    "'''\n",
    "preds and lockbox shape: (9, 50, 576, 4).\n",
    "Axis -3 (50) should be collapsed only in the \n",
    "following cases:\n",
    "    - accuracy\n",
    "    - std. dev.\n",
    "Collapsing of the axis for uncertainty is in\n",
    "models_bachelors.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d901a1",
   "metadata": {},
   "source": [
    "### Accuracy of each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eacadb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n",
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n",
      "data shape: (9, 456, 4)\n",
      "data shape: (9, 456, 4)\n",
      "0 (456,)\n",
      "1 (456,)\n",
      "2 (456,)\n",
      "3 (456,)\n",
      "4 (456,)\n",
      "5 (456,)\n",
      "6 (456,)\n",
      "7 (456,)\n",
      "8 (456,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fa8d45522793>:39: RuntimeWarning: Mean of empty slice.\n",
      "  key = np.array(key).mean(axis=0)\n",
      "/home/pmanivannan/miniconda3/envs/tf/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-3-fa8d45522793>:42: RuntimeWarning: Mean of empty slice.\n",
      "  key = np.array(key).mean(axis=0)\n",
      "<ipython-input-3-fa8d45522793>:45: RuntimeWarning: Mean of empty slice.\n",
      "  key = np.array(key).mean(axis=0)\n",
      "<ipython-input-3-fa8d45522793>:48: RuntimeWarning: Mean of empty slice.\n",
      "  key = np.array(key).mean(axis=0)\n"
     ]
    }
   ],
   "source": [
    "acc_mcdropconnect = {'test': [], 'lockbox': []}\n",
    "acc_mcdropout = {'test': [], 'lockbox': []}\n",
    "acc_ensemble_dropout = {'test': [], 'lockbox': []}\n",
    "acc_duq = {'test': [], 'lockbox': []}\n",
    "acc_flipout = {'test': [], 'lockbox': []}\n",
    "NUM = 50  # Number of prediction sets\n",
    "# Load each prediction set and compute avg accuracy for each set, adding them to list\n",
    "for n in range(NUM):\n",
    "    methods = load_dict_from_hdf5(f'predictions/predictions_duq.h5')\n",
    "    for name, method in methods.items():\n",
    "        isStandard = True\n",
    "        # print(f'y_true: {method[\"test\"][\"labels\"].argmax(axis=-1).shape}, y_pred: {method[\"test\"][\"preds\"].argmax(axis=-1).shape}')\n",
    "        test_accs = get_accuracies(method[\"test\"], isStandard)   # Get test set accuracies\n",
    "        lock_accs = get_accuracies(method[\"lockbox\"], isStandard)\n",
    "        if name == 'mcdropconnect':\n",
    "            acc_mcdropconnect['test'].append(test_accs)\n",
    "            acc_mcdropconnect['lockbox'].append(lock_accs)\n",
    "        elif name == 'mcdropout':\n",
    "            acc_mcdropout['test'].append(test_accs)\n",
    "            acc_mcdropout['lockbox'].append(lock_accs)\n",
    "        elif name == 'standard':\n",
    "            acc_std['test'].append(test_accs)\n",
    "            acc_std['lockbox'].append(lock_accs)\n",
    "        elif name == 'standard_dropconnect':\n",
    "            acc_std_mcdropconnect['test'].append(test_accs)\n",
    "            acc_std_mcdropconnect['lockbox'].append(lock_accs)\n",
    "        elif name == 'flipout':\n",
    "            acc_flipout['test'].append(test_accs)\n",
    "            acc_flipout['lockbox'].append(lock_accs)\n",
    "        elif name == 'duq':\n",
    "            acc_duq['test'].append(test_accs)\n",
    "            acc_duq['lockbox'].append(lock_accs)\n",
    "        else:\n",
    "            acc_ensemble_dropout['test'].append(test_accs)\n",
    "            acc_ensemble_dropout['lockbox'].append(lock_accs)\n",
    "\n",
    "# Only for UQ:\n",
    "for name, key in acc_mcdropconnect.items():\n",
    "    key = np.array(key).mean(axis=0)\n",
    "\n",
    "for name, key in acc_mcdropout.items():\n",
    "    key = np.array(key).mean(axis=0)\n",
    "\n",
    "for name, key in acc_ensemble_dropout.items():\n",
    "    key = np.array(key).mean(axis=0)\n",
    "\n",
    "for name, key in acc_flipout.items():\n",
    "    key = np.array(key).mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duq\n",
      "test set avg acc: 55.421 +/- 9.163\n",
      "lockbox set avg acc: 70.468 +/- 2.929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import round\n",
    "\n",
    "r = 5\n",
    "# print(round(np.std(acc_mcdropconnect[\"test\"]), 5))\n",
    "# print('mcdropout')\n",
    "# print(acc_mcdropout)\n",
    "# print(f'test set avg acc: {round(np.mean(acc_mcdropout[\"test\"]), r) * 100} +/- {round(np.std(acc_mcdropout[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_mcdropout[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_mcdropout[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "# print('mcdropconnect')\n",
    "# print(f'test set avg acc: {round(np.mean(acc_mcdropconnect[\"test\"]), r) * 100} +/- {round(np.std(acc_mcdropconnect[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_mcdropconnect[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_mcdropconnect[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "# print('standard_dropout')\n",
    "# print(f'test set avg acc: {round(np.mean(acc_std[\"test\"]), r) * 100} +/- {round(np.std(acc_std[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_std[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_std[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "\n",
    "# print('standard_dropconnect')\n",
    "# print(f'test set avg acc: {round(np.mean(acc_std_mcdropconnect[\"test\"]), r) * 100} +/- {round(np.std(acc_std_mcdropconnect[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_std_mcdropconnect[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_std_mcdropconnect[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "\n",
    "# print('ensemble_dropout')\n",
    "# print(f'test set avg acc: {round(np.mean(acc_ensemble_dropout[\"test\"]), r) * 100} +/- {round(np.std(acc_ensemble_dropout[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_ensemble_dropout[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_ensemble_dropout[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "\n",
    "print('duq')\n",
    "print(f'test set avg acc: {round(np.mean(acc_duq[\"test\"]), r) * 100} +/- {round(np.std(acc_duq[\"test\"]), r) * 100}')\n",
    "print(f'lockbox set avg acc: {round(np.mean(acc_duq[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_duq[\"lockbox\"]), r) * 100}\\n')\n",
    "\n",
    "# print('flipout')\n",
    "# print(f'test set avg acc: {round(np.mean(acc_flipout[\"test\"]), r) * 100} +/- {round(np.std(acc_flipout[\"test\"]), r) * 100}')\n",
    "# print(f'lockbox set avg acc: {round(np.mean(acc_flipout[\"lockbox\"]), r) * 100} +/- {round(np.std(acc_flipout[\"lockbox\"]), r) * 100}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88f768",
   "metadata": {},
   "source": [
    "### Average normalised predictive entropy\n",
    "\n",
    "And associated normalised intersection for comparison [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pred_entropy_plots(dataset, method, unc_method):\n",
    "    bin_size = 0.05\n",
    "    entropy_correct = []\n",
    "    entropy_wrong = []\n",
    "    # For data loading standard predictions are in a single file\n",
    "    if 'standard' in method:\n",
    "        N = 1\n",
    "        isStandard = True\n",
    "    else:\n",
    "        N = 50\n",
    "        isStandard = False\n",
    "\n",
    "    # Iterate over all prediction sets.\n",
    "    if not isStandard:\n",
    "        for n in range(N):\n",
    "            methods = load_predictions(n, isStandard)\n",
    "            data = methods[method][dataset]\n",
    "            entropy = get_uncertainty(data,unc_method)\n",
    "            Y_true = data['labels']    # shape: (9,576,4)\n",
    "            corrects = get_corrects(Y_true, data['preds'], axis=-1) # Get corrects across ALL subjects\n",
    "            # Append the nth prediction's uncertainty estimations\n",
    "            entropy_correct.append(entropy[corrects])\n",
    "            entropy_wrong.append(entropy[~corrects])\n",
    "            # For distribution plots of predictive entropy\n",
    "    else:\n",
    "        methods = load_predictions(0, isStandard)\n",
    "        data = methods[method][dataset]\n",
    "        print()\n",
    "        entropy = get_uncertainty(data, unc_method)\n",
    "        Y_true = data['labels']    # shape: (9,576,4)\n",
    "        corrects = get_corrects(Y_true, data['preds'], axis=-1) # Get corrects across ALL subjects\n",
    "        # Append the nth prediction's uncertainty estimations\n",
    "        entropy_correct.append(entropy[corrects])\n",
    "        entropy_wrong.append(entropy[~corrects])\n",
    "\n",
    "    '''\n",
    "    Check for data mismatch: entropy_correct is probably a list of np arrays instead of \n",
    "    1 cohesive np array \n",
    "    '''\n",
    "    entropy_correct = np.hstack(entropy_correct)\n",
    "    entropy_wrong = np.hstack(entropy_wrong)\n",
    "    r = 5\n",
    "    unc_cor = np.mean(entropy_correct)\n",
    "    unc_cor_std = np.std(entropy_correct)\n",
    "    unc_in = np.mean(entropy_wrong)\n",
    "    unc_in_std = np.std(entropy_wrong)\n",
    "    print(f\"{dataset} avg. {unc_method} correct: {unc_cor:.5f} +/ {unc_cor_std:.5f}\")\n",
    "    print(f\"{dataset} avg. {unc_method} wrong: {unc_in:.5f} +/ {unc_in_std:.5f}\")\n",
    "\n",
    "    # hist_data = [entropy_correct, entropy_wrong]    \n",
    "    # group_labels = ['Correct', 'Incorrect']\n",
    "\n",
    "    # # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "    # hist_correct, bins_correct, _ = plt.hist(entropy_correct, bins=20, density=True, alpha=0.5, label='Correct')\n",
    "    # hist_wrong, bins_wrong, _ = plt.hist(entropy_wrong, bins=20, density=True, alpha=0.5, label='Wrong')\n",
    "    # plt.legend()\n",
    "    # # plt.show()\n",
    "\n",
    "    # # Calculate overlap using histogram intersection\n",
    "    # overlap = np.sum(np.minimum(hist_correct, hist_wrong))\n",
    "\n",
    "    # # Normalize overlap between 0 and 1\n",
    "    # normalized_overlap = overlap / np.sum(hist_correct)\n",
    "\n",
    "    # print(\"Overlap:\", normalized_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['mcdropconnect', 'mcdropout', 'standard', 'standard_dropconnect']\n",
    "\n",
    "for method in methods:\n",
    "    print(f'{method}\\n')\n",
    "    # False makes calculations off of mutual information\n",
    "    avg_pred_entropy_plots('test', method, 'shannon-entropy')\n",
    "    avg_pred_entropy_plots('lockbox', method, 'shannon-entropy')\n",
    "    # avg_pred_entropy_plots('lockbox', method, 'mutual-information')\n",
    "    # avg_pred_entropy_plots('lockbox', method, 'shannon-entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7dbf67",
   "metadata": {},
   "source": [
    "### PLOT ACC COV ON X AND Y AXIS, NOT THRESHOLD\n",
    "These plots are to select a threshold for treating uncertainty as a binary classification task. Once the threshold is selected from the plot, you can compute the uncertainty accuracy, precision, sensitivity, specificity ROC plots and AUROC.\n",
    "\n",
    "So accuracy and coverage will be computed for predictions that are above a certain uncertainty threshold\n",
    "\n",
    "Explanations for very poor entropy based accuracy-coverage plots:\n",
    "Because of high inter-subject variability, the specific model is unable to fully learn subject-independent features, leading to a high degree of epistemic uncertainty (my theory). Maybe I can confirm this by disentangling uncertainty... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (9*50, 50, 576, 4)\n",
    "'''\n",
    "def make_roc_plot(y_true, y_pred, isStandard, unc_method):\n",
    "    '''\n",
    "    y_pred can be either of shape (50, 9, 50, 576, 4) or  (9, 50, 576, 4). We need it in shape (X, 4).\n",
    "    y_true can be either of shape (50, 9, 576, 4) or (9, 576, 4).\n",
    "    So apply same algorithm to get these sets into the shape (X, 4)\n",
    "    '''\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    # print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}')\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    unc = get_uncertainty(y_pred, unc_method).flatten()\n",
    "    y_true = get_in_shape(y_true)\n",
    "    y_pred = get_in_shape(y_pred) if isStandard else get_in_shape(y_pred.mean(axis=-3))\n",
    "    \n",
    "    # print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}, certains: {unc.shape}')\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    # fig1, ax1 = plt.subplots()\n",
    "    # hist_correct, bins_correct, _ = ax1.hist(auc, bins=10, density=False, alpha=0.5, label='Correct')\n",
    "    # fig1.show()\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "\n",
    "'''\n",
    "I calculate AUROC and plot ROC separately because I want to get\n",
    "mean AUROC of all 50 prediction sets along with their variance.\n",
    "Then I plot ROC with all 50 prediction sets.\n",
    "'''\n",
    "def roc_plot_and_auroc(method, key, unc_method):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    aucs_lst = []\n",
    "    # isStandard = True if 'standard' in method else False\n",
    "    isStandard = False\n",
    "    # num_predictions = 50 if not isStandard else 1\n",
    "    num_predictions = 1\n",
    "    # creation of set of 50 predictions, as well as AUROC score calculation\n",
    "    for n in range(num_predictions):\n",
    "        # methods = load_predictions(n, 'duq')\n",
    "        methods = load_dict_from_hdf5(f'predictions/predictions_ensemble_dropout.h5')\n",
    "        data = methods[method][key]\n",
    "        tpr, fpr = make_roc_plot(data['labels'], data['preds'], isStandard, unc_method)\n",
    "        # print(f'y_true shape: {y_true_roc.shape} y_pred: {y_pred_roc.shape}')\n",
    "        auroc_score = auc(tpr, fpr)\n",
    "        aucs_lst.append(auroc_score)\n",
    "        y_pred.append(data['preds'])\n",
    "        y_true.append(data['labels'])\n",
    "\n",
    "    tpr, fpr = make_roc_plot(np.vstack(y_true), np.vstack(y_pred), isStandard, unc_method)\n",
    "\n",
    "    return tpr, fpr, aucs_lst\n",
    "\n",
    "\n",
    "# aucs_test = {'predictive-entropy':\n",
    "#           {'mcdropconnect':[], 'mcdropout':[], 'standard':[], 'standard_dropconnect':[]},\n",
    "#           'shannon-entropy':\n",
    "#           {'mcdropconnect':[], 'mcdropout':[], 'standard':[], 'standard_dropconnect':[]},\n",
    "#           'mutual-information':\n",
    "#           {'mcdropconnect':[], 'mcdropout':[], 'standard':[], 'standard_dropconnect':[]}\n",
    "#         }\n",
    "# aucs_test = {'predictive-entropy': {'mcdropconnect':[], 'mcdropout':[], 'standard':[], 'standard_dropconnect':[]}}\n",
    "# methods = {'mcdropconnect':'C0', 'mcdropout':'C1', 'standard':'C4', 'standard_dropconnect':'C9'}\n",
    "# aucs_test = {'predictive-entropy': {'ensemble_dropout': []}}\n",
    "# aucs_test = {'predictive-entropy': {'duq': []}}\n",
    "aucs_test = {'predictive-entropy': {'ensemble_dropout': []}, 'shannon-entropy': {'ensemble_dropout': []}, 'mutual-information': {'ensemble_dropout': []}}\n",
    "# fig1, ax1 = plt.subplots(2, squeeze=False, figsize=(10, 20))\n",
    "# ax1 = ax1.flatten()\n",
    "key = \"test\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        tpr, fpr, ret_aucs = roc_plot_and_auroc(method, key, unc_name)\n",
    "        print(f'{key} AUC: {round(np.mean(ret_aucs), r) * 100} +/- {round(np.std(ret_aucs), r) * 100}')\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "        print(method)\n",
    "        r = 6\n",
    "        # ax1[0].plot(tpr, fpr, color=methods[method])\n",
    "\n",
    "key = \"lockbox\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        r = 6\n",
    "        tpr, fpr, ret_aucs = roc_plot_and_auroc(method, key, unc_name)\n",
    "        print(f'{key} AUC: {round(np.mean(ret_aucs), r) * 100} +/- {round(np.std(ret_aucs), r) * 100}')\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "        print(method)\n",
    "        # ax1[1].plot(tpr, fpr, color=methods[method])\n",
    "\n",
    "# red_patch = mpatches.Patch(color=methods['mcdropconnect'], label='MC-DropConnect')\n",
    "# green_patch = mpatches.Patch(color=methods['mcdropout'], label='MC-Dropout')\n",
    "# blue_patch = mpatches.Patch(color=methods['standard'], label='Standard Dropout')\n",
    "# yellow_patch = mpatches.Patch(color=methods['standard_dropconnect'], label='Standard Dropconnect')\n",
    "\n",
    "# ax1[0].legend(handles=[red_patch, green_patch, blue_patch, yellow_patch], fontsize=20)\n",
    "# ax1[0].set_title(f'Out-of-population ROC', fontsize=35)\n",
    "# ax1[0].set_xlabel(\"FPR\", fontsize=30)\n",
    "# ax1[0].set_ylabel(\"TPR\", fontsize=30)\n",
    "\n",
    "# ax1[1].legend(handles=[red_patch, green_patch, blue_patch, yellow_patch], fontsize=20)\n",
    "# ax1[1].set_title(f'Within-population ROC', fontsize=35)\n",
    "# ax1[1].set_xlabel(\"FPR\", fontsize=30)\n",
    "# ax1[1].set_ylabel(\"TPR\", fontsize=30)\n",
    "\n",
    "# # plt.rcParams.update({'font.size': 22})\n",
    "# # fig1.savefig(f'roc_plot_pred_entropy_w_10_h_20.pdf')\n",
    "# ax1[0].tick_params(axis='x', labelsize=20)\n",
    "# ax1[0].tick_params(axis='y', labelsize=20)\n",
    "# ax1[1].tick_params(axis='x', labelsize=20)\n",
    "# ax1[1].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "# fig1.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88310a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig(f'roc_plot_pred_entropy_w_10_h_20_large.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if there is a significant difference between the AUROCs of two methods with a certain metric on one set, need to construct and save a MATLAB struct with two elements:\n",
    "\n",
    "- spsizes: 2 x 1 vector with samples sizes for X and Y, uncertainties and targets\n",
    "- ratings: K x N matrix. K is uncertainties/targets of each model, it is the row. N is the sum of len(X) and len(Y) and first len(X) elements are uncertainties and last len(Y) elements are targets\n",
    "\n",
    "Then I gotta save this data as a MATLAB struct while in python somehow\n",
    "\n",
    "Things I want to compare for test and lockbox:\n",
    "- MC-Dropout: mutual information and shannon entropy\n",
    "- MC-DropConnect: mutual information and shannon entropy\n",
    "\n",
    "So 2 separate files to save, one for test and the other for lockbox\n",
    "\n",
    "y_true/ground truth labels will be 0, 1. And will be 1 when y_true != y_pred and 0 when it isn't. So basically, 1 for all incorrects (which should be uncertains) and 0 for all corrects (which should be certains)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per subject scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per-subject uncertainties and AUROC\n",
    "This is exactly what I need:\n",
    "    - Per subject AUROC. This can only be done with array of shape (9, 576).\n",
    "        - start w/ (50, 9, 50, 576, 4) for a method.\n",
    "        - Mean axis=0 -> (9, 50, 576, 4)\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "        - For each subject in axis 0, calculate AUROC to get final array of (9, 1)\n",
    "    - Array of shape (9, 1) for uncertanties\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.patches as mpatches\n",
    "import scipy.stats as stats\n",
    "from numpy import round\n",
    "\n",
    "def load_all_predictions():\n",
    "    predictions = {'mcdropout': \n",
    "            {'test': {'preds':[], 'labels':[]}, \n",
    "                'lockbox':{'preds':[], 'labels':[]}},\n",
    "                'mcdropconnect': \n",
    "            {'test': {'preds':[], 'labels':[]}, \n",
    "                'lockbox':{'preds':[], 'labels':[]}},\n",
    "                'standard': \n",
    "            {'test': {'preds':[], 'labels':[]}, \n",
    "                'lockbox':{'preds':[], 'labels':[]}},\n",
    "                'standard_dropconnect': \n",
    "            {'test': {'preds':[], 'labels':[]}, \n",
    "                'lockbox':{'preds':[], 'labels':[]}}\n",
    "            }\n",
    "    # Load all UQ method predictions\n",
    "    N = 50\n",
    "    for n in range(N):\n",
    "        dataset = load_predictions(n, False)\n",
    "        # No need to append the labels because they're the same each time.\n",
    "        # So only need to append them once.\n",
    "        predictions['mcdropout']['test']['preds'].append(dataset['mcdropout']['test']['preds'])\n",
    "        predictions['mcdropout']['lockbox']['preds'].append(dataset['mcdropout']['lockbox']['preds'])\n",
    "        predictions['mcdropconnect']['test']['preds'].append(dataset['mcdropconnect']['test']['preds'])\n",
    "        predictions['mcdropconnect']['lockbox']['preds'].append(dataset['mcdropconnect']['lockbox']['preds'])\n",
    "\n",
    "    # Load all Standard method predictions\n",
    "    dataset = load_predictions(1, True)\n",
    "    predictions['standard']['test']['preds'].append(dataset['standard']['test']['preds'])\n",
    "    predictions['standard']['lockbox']['preds'].append(dataset['standard']['lockbox']['preds'])\n",
    "    predictions['standard_dropconnect']['test']['preds'].append(dataset['standard_dropconnect']['test']['preds'])\n",
    "    predictions['standard_dropconnect']['lockbox']['preds'].append(dataset['standard_dropconnect']['lockbox']['preds'])\n",
    "\n",
    "    # Load all the labels once into their respective method dicts\n",
    "    for name, method in predictions.items():\n",
    "        # standard labels are same as UQ method labels.\n",
    "        method['test']['labels'] = dataset['standard']['test']['labels']\n",
    "        method['lockbox']['labels'] = dataset['standard']['lockbox']['labels']\n",
    "        # convert relevant lists to numpy arrays\n",
    "        method['test']['preds'] = np.array(method['test']['preds'])\n",
    "        method['lockbox']['preds'] = np.array(method['lockbox']['preds'])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (50, 576, 4)\n",
    "'''\n",
    "def get_fpr_tpr(y_true, y_pred, unc, isStandard):\n",
    "    '''\n",
    "    y_pred can be either of shape (50, 9, 50, 576, 4) or  (9, 50, 576, 4). We need it in shape (X, 4).\n",
    "    y_true can be either of shape (50, 9, 576, 4) or (9, 576, 4).\n",
    "    So apply same algorithm to get these sets into the shape (X, 4)\n",
    "    '''\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    y_pred = y_pred if isStandard else y_pred.mean(axis=-3)\n",
    "    \n",
    "    # print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}, certains: {unc.shape}')\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "def get_auroc(y_true, y_pred, unc, isStandard):\n",
    "    tpr, fpr = get_fpr_tpr(y_true, y_pred, unc, isStandard)\n",
    "    return auc(tpr, fpr)\n",
    "\n",
    "def per_subject_metrics(data, isStandard):\n",
    "    key_set = data[key]        # Whether lockbox or preds of the method\n",
    "    y_true = key_set['labels']\n",
    "    y_preds = key_set['preds'].mean(axis=0)     # Take avg of 50 pred. sets if UQ preds\n",
    "    unc = predictive_uncertainty(y_preds, 'predictive-entropy')\n",
    "    per_subject_aucs = []\n",
    "    # print(y_preds.shape)\n",
    "    for subject_id in range(y_preds.shape[0]):\n",
    "        per_subject_aucs.append(get_auroc(y_true[subject_id], y_preds[subject_id], unc[subject_id], isStandard))\n",
    "\n",
    "    \n",
    "    return np.array(per_subject_aucs), unc.mean(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "'''\n",
    "data: (50, 9, 50, 576, 4)\n",
    "method: 'mcdropconnect'/'mcdropout'/'standard'/'standard_dropconnect'\n",
    "key: 'test'/'lockbox'\n",
    "'''\n",
    "def do_everything(data, method, key):\n",
    "    # data shape for UQ preds: (50, 9, 50, 576, 4)\n",
    "    aucs_lst = []\n",
    "    isStandard = True if 'standard' in method else False\n",
    "    aurocs, uncertainties = per_subject_metrics(data, isStandard)\n",
    "    return aurocs, uncertainties\n",
    "\n",
    "\n",
    "aucs = {'mcdropconnect':[], 'mcdropout':[], 'standard':[], 'standard_dropconnect':[]}\n",
    "uncertainties = {'mcdropconnect':[], 'mcdropout':[], 'std':[], 'standard_dropconnect':[]}\n",
    "methods = {'mcdropconnect':'red', 'mcdropout':'green', 'standard':'blue', 'standard_dropconnect':'yellow'}\n",
    "fig1, ax1 = plt.subplots()\n",
    "key = \"test\"\n",
    "data = load_all_predictions()       # all prediction sets across all methods into a single object\n",
    "for method, values in data.items():\n",
    "    aurocs, uncs = do_everything(values, method, key)\n",
    "    # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "    print(method)\n",
    "    r = 6\n",
    "    aucs[method] = aurocs\n",
    "    uncertainties[method] = uncs\n",
    "    # print(f'{key} set avg AUROC: {np.mean(aucs)} +/- {np.std(aucs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method, values in aucs.items():\n",
    "    print(f'\\n\\n{method}\\n aucs:{values}\\n uncs: {uncertainties[method]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
