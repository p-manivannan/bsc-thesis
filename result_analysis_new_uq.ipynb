{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=1     \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "from result_analysis_functions import *\n",
    "from models_bachelors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidenote:\n",
    "- isStandard is True for any method outputting a 3D array (9, 576, 4) when inputs are of shape (9, 576). It is therefore True for standard, standard_dropconnect and DUQ, while False for every other method. This is because the other methods, from their prediction sets, have either 4 or 5 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "predictive-entropy\n",
      "y_true: (5184, 4), y_pred: (5184, 4), certains: (5184,)\n",
      "y_true: (5184, 4), y_pred: (5184, 4), certains: (5184,)\n",
      "test AUC: 65.70949999999999\n",
      "lockbox\n",
      "predictive-entropy\n",
      "y_true: (4104, 4), y_pred: (4104, 4), certains: (4104,)\n",
      "y_true: (4104, 4), y_pred: (4104, 4), certains: (4104,)\n",
      "lockbox AUC: 73.1019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (9*50, 50, 576, 4)\n",
    "'''\n",
    "def make_roc_plot(y_true, y_pred, isStandard, unc_method):\n",
    "    '''\n",
    "    y_pred can be either of shape (50, 9, 50, 576, 4) or  (9, 50, 576, 4). We need it in shape (X, 4).\n",
    "    y_true can be either of shape (50, 9, 576, 4) or (9, 576, 4).\n",
    "    So apply same algorithm to get these sets into the shape (X, 4)\n",
    "    '''\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    unc = y_pred.max(axis=-1).flatten()\n",
    "    # unc = get_uncertainty(y_pred, unc_method, isStandard).flatten()\n",
    "    y_true = get_in_shape(y_true)\n",
    "    # y_pred = get_in_shape(y_pred) if isStandard else get_in_shape(y_pred.mean(axis=-3))\n",
    "    y_pred = get_in_shape(y_pred)\n",
    "    print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}, certains: {unc.shape}')\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    # fig1, ax1 = plt.subplots()\n",
    "    # hist_correct, bins_correct, _ = ax1.hist(auc, bins=10, density=False, alpha=0.5, label='Correct')\n",
    "    # fig1.show()\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "\n",
    "'''\n",
    "I calculate AUROC and plot ROC separately because I want to get\n",
    "mean AUROC of all 50 prediction sets along with their variance.\n",
    "Then I plot ROC with all 50 prediction sets.\n",
    "'''\n",
    "def roc_plot_and_auroc(method, key, unc_method):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    aucs_lst = []\n",
    "    # num_predictions = 50 if not isStandard else 1\n",
    "    num_predictions = 1\n",
    "    # creation of set of 50 predictions, as well as AUROC score calculation\n",
    "    for n in range(num_predictions):\n",
    "        # methods = load_predictions(n, 'duq')\n",
    "        methods = load_dict_from_hdf5('predictions/predictions_duq.h5')\n",
    "        data = methods[method][key]\n",
    "        isStandard = checkIfStandard(method)\n",
    "        tpr, fpr = make_roc_plot(data['labels'], data['preds'], isStandard, unc_method)\n",
    "        # print(f'y_true shape: {y_true_roc.shape} y_pred: {y_pred_roc.shape}')\n",
    "        auroc_score = auc(tpr, fpr)\n",
    "        aucs_lst.append(auroc_score)\n",
    "        y_pred.append(data['preds'])\n",
    "        y_true.append(data['labels'])\n",
    "\n",
    "    tpr, fpr = make_roc_plot(np.vstack(y_true), np.vstack(y_pred), isStandard, unc_method)\n",
    "\n",
    "    return tpr, fpr\n",
    "\n",
    "\n",
    "aucs_test = {'predictive-entropy': {'duq': []}}        # for ensemble, isStandard=False, unc=get_uncertainty(y_preds, unc_method).flatten()\n",
    "key = \"test\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        tpr, fpr = roc_plot_and_auroc(method, key, unc_name)\n",
    "        r = 6\n",
    "        print(f'{key} AUC: {np.round(1 - auc(tpr, fpr), r) * 100}')         \n",
    "        '''\n",
    "        For some reason, DUQ has 65 AUROC for test and 73 AUROC for lockbox only when it's 1-AUC. Where \n",
    "        AUC is thresholded with maximum on axis -1 as the uncertainty.\n",
    "        The 'right' way of selecting uncertainty as the lowest distance, so minimum on axis -1 has a score of\n",
    "        55 and 65...\n",
    "        '''\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "\n",
    "key = \"lockbox\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        tpr, fpr = roc_plot_and_auroc(method, key, unc_name)\n",
    "        r = 6\n",
    "        print(f'{key} AUC: {np.round(1 - auc(tpr, fpr), r) * 100}')\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = load_dict_from_hdf5('predictions/predictions_duq.h5')\n",
    "data = methods['duq']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 576, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isStandard = True   # Because DUQ is only 1 forward pass\n",
    "\n",
    "acc = []\n",
    "print(f'data shape: {data[\"preds\"].shape}')\n",
    "data = avg_forward_passes(data) if not isStandard else data\n",
    "print(f'data shape: {data[\"preds\"].shape}')\n",
    "y_preds = data[\"preds\"].argmax(axis=-1)\n",
    "y_trues = data[\"labels\"].argmax(axis=-1)\n",
    "\n",
    "# Get accuracy of each subject\n",
    "for idx, subject in enumerate(y_trues):\n",
    "    print(idx, subject.shape)\n",
    "    score = accuracy_score(y_pred=subject, y_true=y_preds[idx], normalize=True)\n",
    "    acc.append(score)\n",
    "\n",
    "data['labels'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-subject AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "\n",
      "standard\n",
      "predictive-entropy\n",
      "test set avg AUROC: 67.46 +/- 4.646\n",
      "shannon-entropy\n",
      "test set avg AUROC: 67.46 +/- 4.646\n",
      "\n",
      "mcdropout\n",
      "predictive-entropy\n",
      "test set avg AUROC: 67.43 +/- 4.611\n",
      "mutual-information\n",
      "test set avg AUROC: 66.6 +/- 4.164\n",
      "shannon-entropy\n",
      "test set avg AUROC: 67.43 +/- 4.613\n",
      "\n",
      "standard_dropconnect\n",
      "predictive-entropy\n",
      "test set avg AUROC: 68.23 +/- 4.532\n",
      "shannon-entropy\n",
      "test set avg AUROC: 68.23 +/- 4.532\n",
      "\n",
      "mcdropconnect\n",
      "predictive-entropy\n",
      "test set avg AUROC: 68.48 +/- 4.625\n",
      "mutual-information\n",
      "test set avg AUROC: 66.82 +/- 5.311\n",
      "shannon-entropy\n",
      "test set avg AUROC: 68.48 +/- 4.626\n",
      "\n",
      "flipout\n",
      "predictive-entropy\n",
      "test set avg AUROC: 67.76 +/- 5.232\n",
      "mutual-information\n",
      "test set avg AUROC: 64.45 +/- 4.278\n",
      "shannon-entropy\n",
      "test set avg AUROC: 67.76 +/- 5.228\n",
      "\n",
      "ensemble_dropout\n",
      "predictive-entropy\n",
      "test set avg AUROC: 67.39 +/- 5.446\n",
      "mutual-information\n",
      "test set avg AUROC: 63.86 +/- 4.354\n",
      "shannon-entropy\n",
      "test set avg AUROC: 67.29 +/- 5.564\n",
      "\n",
      "duq\n",
      "predictive-entropy\n",
      "test set avg AUROC: 56.26 +/- 3.247\n",
      "mutual-information\n",
      "test set avg AUROC: 56.26 +/- 3.247\n",
      "shannon-entropy\n",
      "test set avg AUROC: 56.26 +/- 3.247\n",
      "lockbox\n",
      "\n",
      "standard\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 76.07 +/- 2.918\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 76.07 +/- 2.918\n",
      "\n",
      "mcdropout\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 76.07 +/- 2.927\n",
      "mutual-information\n",
      "lockbox set avg AUROC: 74.24 +/- 3.398\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 76.06 +/- 2.927\n",
      "\n",
      "standard_dropconnect\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 75.44 +/- 2.691\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 75.44 +/- 2.691\n",
      "\n",
      "mcdropconnect\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 75.3 +/- 3.303\n",
      "mutual-information\n",
      "lockbox set avg AUROC: 73.33 +/- 2.835\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 75.29 +/- 3.297\n",
      "\n",
      "flipout\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 75.61 +/- 2.414\n",
      "mutual-information\n",
      "lockbox set avg AUROC: 70.56 +/- 2.488\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 75.61 +/- 2.418\n",
      "\n",
      "ensemble_dropout\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 76.92 +/- 2.868\n",
      "mutual-information\n",
      "lockbox set avg AUROC: 70.02 +/- 2.064\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 76.66 +/- 3.046\n",
      "\n",
      "duq\n",
      "predictive-entropy\n",
      "lockbox set avg AUROC: 61.38 +/- 2.795\n",
      "mutual-information\n",
      "lockbox set avg AUROC: 61.38 +/- 2.795\n",
      "shannon-entropy\n",
      "lockbox set avg AUROC: 61.38 +/- 2.795\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Per-subject uncertainties and AUROC\n",
    "This is exactly what I need:\n",
    "    - Per subject AUROC. This can only be done with array of shape (9, 576).\n",
    "        - start w/ (50, 9, 50, 576, 4) for a method.\n",
    "        - Mean axis=0 -> (9, 50, 576, 4)\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "        - For each subject in axis 0, calculate AUROC to get final array of (9, 1)\n",
    "    - Array of shape (9, 1) for uncertanties\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (50, 576, 4)\n",
    "'''\n",
    "def get_fpr_tpr(y_true, y_pred, unc, isStandard):\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    y_pred = get_in_shape(y_pred.mean(axis=0)) if isStandard not in [1, 2] else y_pred     # Take mean of axis with forward passes with methods aren't standard and DUQ\n",
    "    y_true = get_in_shape(y_true)\n",
    "\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "def get_auroc(y_true, y_pred, unc, isStandard):\n",
    "    tpr, fpr = get_fpr_tpr(y_true, y_pred, unc, isStandard)\n",
    "    return auc(tpr, fpr)\n",
    "\n",
    "def per_subject_metrics(data, method, key, unc_method):\n",
    "    key_set = data[key]        # Whether lockbox or preds of the method\n",
    "    y_true = key_set['labels']\n",
    "    isStandard = checkIfStandard(method)\n",
    "    # Average the set of 50 predictions for flipout and MC methods\n",
    "    y_preds = key_set['preds'].mean(axis=0) if 'mc' in method or 'flipout' in method else key_set['preds']\n",
    "    unc = get_uncertainty(y_preds, unc_method, isStandard)\n",
    "    per_subject_aucs = []\n",
    "    for subject_id in range(y_preds.shape[0]):\n",
    "        per_subject_aucs.append(get_auroc(y_true[subject_id], y_preds[subject_id], unc[subject_id], isStandard))\n",
    "\n",
    "    return np.array(per_subject_aucs), unc.mean(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "data: (50, 9, 50, 576, 4)\n",
    "method: 'mcdropconnect'/'mcdropout'/'standard'/'standard_dropconnect'\n",
    "key: 'test'/'lockbox'\n",
    "'''\n",
    "def do_everything(data, method, key, unc_method):\n",
    "    # data shape for UQ preds: (50, 9, 50, 576, 4)\n",
    "    aurocs, uncertainties = per_subject_metrics(data, method, key, unc_method)\n",
    "    return aurocs, uncertainties\n",
    "\n",
    "import re\n",
    "\n",
    "def load_predictions_TEST(method, num=None):\n",
    "    if 'standard' in method:        # Like standard_dropout/standard/standard_dropconnect\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_standard.h5')\n",
    "    elif 'ensemble' in method:      # currently only ensemble based on regular dropout\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_ensemble_dropout.h5')\n",
    "    elif 'duq' in method:\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_duq.h5')\n",
    "    elif num != None:                           # Only cases are MC-Dropout and MC-DropConnect\n",
    "        if 'standard' in method:\n",
    "           return load_dict_from_hdf5(f'predictions/predictions_{num}.h5')\n",
    "        else:   # Only flipout satisfies this condition for now\n",
    "           return load_dict_from_hdf5(f'predictions/flipout/predictions_flipout_{num}.h5')\n",
    "    else:\n",
    "      reg = re.compile(r\"\\d+(?=\\.)\")\n",
    "      directory = f'predictions/predictions_' if 'flipout' not in method else f'predictions/flipout/predictions_flipout_'\n",
    "      if 'flipout' in method:\n",
    "        num = max([int(reg.search(x).group()) for x in os.listdir('predictions/flipout') if reg.search(x) != None]) + 1\n",
    "      else:\n",
    "        num = max([int(reg.search(x).group()) for x in os.listdir('predictions') if reg.search(x) != None]) + 1\n",
    "      ret = {method: {'test': {'preds':[], 'labels':[]}, 'lockbox': {'preds':[], 'labels':[]}}}\n",
    "      for n in range(num):\n",
    "          temp_holder = load_dict_from_hdf5(directory + f'{n}.h5')\n",
    "          ret[method]['test']['preds'].append(temp_holder[method]['test']['preds'])\n",
    "          ret[method]['lockbox']['preds'].append(temp_holder[method]['lockbox']['preds'])\n",
    "          if n == 0:\n",
    "            ret[method]['test']['labels'] = temp_holder[method]['test']['labels']\n",
    "            ret[method]['lockbox']['labels'] =temp_holder[method]['lockbox']['labels']\n",
    "\n",
    "      ret[method]['test']['preds'] = np.array(ret[method]['test']['preds'])\n",
    "      ret[method]['lockbox']['preds'] = np.array(ret[method]['lockbox']['preds'])\n",
    "      return ret\n",
    "\n",
    "import copy\n",
    "\n",
    "dicts_temp = {'standard':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'mcdropout':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'standard_dropconnect':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'mcdropconnect':{'aucs': \n",
    "                          {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'flipout': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}},\n",
    "        'ensemble_dropout': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'duq': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}}\n",
    "\n",
    "dicts = {}\n",
    "dicts['test'] = copy.deepcopy(dicts_temp)\n",
    "dicts['lockbox'] = copy.deepcopy(dicts_temp)\n",
    "for key, results in dicts.items():          # Iterate through keys\n",
    "    print(key)\n",
    "    for method, values in results.items():  # Iterate through the result holding structure\n",
    "        print(f'\\n{method}')\n",
    "        data = load_predictions_TEST(method)[method]        # TO-DO: Data loading procedure is error free. But does it work? Remains to be seen...\n",
    "        # TO-DO:\n",
    "        # BUG FIX THE REST OF THE CODE BELOW THIS COMMENT FOR PER SUBJECT AUROCS\n",
    "        unc_methods = values['aucs']\n",
    "        for unc, lst in unc_methods.items():\n",
    "            if unc == 'mutual-information' and 'standard' in method:\n",
    "                continue\n",
    "            print(unc)\n",
    "            aurocs, _ = do_everything(data, method, key, unc)\n",
    "            # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "            r = 2\n",
    "            lst = aurocs\n",
    "            print(f'{key} set avg AUROC: {round(np.mean(aurocs) * 100, r)} +/- {round(np.std(aurocs) * 100, r + 1)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
