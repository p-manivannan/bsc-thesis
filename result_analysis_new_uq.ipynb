{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=1     \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "from result_analysis_functions import *\n",
    "from models_bachelors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidenote:\n",
    "- isStandard is True for any method outputting a 3D array (9, 576, 4) when inputs are of shape (9, 576). It is therefore True for standard, standard_dropconnect and DUQ, while False for every other method. This is because the other methods, from their prediction sets, have either 4 or 5 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "predictive-entropy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test AUC: 67.61749999999999\n",
      "lockbox\n",
      "predictive-entropy\n",
      "lockbox AUC: 76.8438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (9*50, 50, 576, 4)\n",
    "'''\n",
    "def make_roc_plot(y_true, y_pred, isStandard, unc_method):\n",
    "    '''\n",
    "    y_pred can be either of shape (50, 9, 50, 576, 4) or  (9, 50, 576, 4). We need it in shape (X, 4).\n",
    "    y_true can be either of shape (50, 9, 576, 4) or (9, 576, 4).\n",
    "    So apply same algorithm to get these sets into the shape (X, 4)\n",
    "    '''\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    unc = get_uncertainty(y_pred, unc_method, isStandard).flatten()\n",
    "    y_true = get_in_shape(y_true)\n",
    "    y_pred = get_in_shape(y_pred) if isStandard else get_in_shape(y_pred.mean(axis=-3))\n",
    "    \n",
    "    # print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}, certains: {unc.shape}')\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    # fig1, ax1 = plt.subplots()\n",
    "    # hist_correct, bins_correct, _ = ax1.hist(auc, bins=10, density=False, alpha=0.5, label='Correct')\n",
    "    # fig1.show()\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "\n",
    "'''\n",
    "I calculate AUROC and plot ROC separately because I want to get\n",
    "mean AUROC of all 50 prediction sets along with their variance.\n",
    "Then I plot ROC with all 50 prediction sets.\n",
    "'''\n",
    "def roc_plot_and_auroc(method, key, unc_method):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    aucs_lst = []\n",
    "    # num_predictions = 50 if not isStandard else 1\n",
    "    num_predictions = 1\n",
    "    # creation of set of 50 predictions, as well as AUROC score calculation\n",
    "    for n in range(num_predictions):\n",
    "        # methods = load_predictions(n, 'duq')\n",
    "        methods = load_dict_from_hdf5('predictions/predictions_ensemble_dropout.h5')\n",
    "        data = methods[method][key]\n",
    "        isStandard = checkIfStandard(method)\n",
    "        tpr, fpr = make_roc_plot(data['labels'], data['preds'], isStandard, unc_method)\n",
    "        # print(f'y_true shape: {y_true_roc.shape} y_pred: {y_pred_roc.shape}')\n",
    "        auroc_score = auc(tpr, fpr)\n",
    "        aucs_lst.append(auroc_score)\n",
    "        y_pred.append(data['preds'])\n",
    "        y_true.append(data['labels'])\n",
    "\n",
    "    tpr, fpr = make_roc_plot(np.vstack(y_true), np.vstack(y_pred), isStandard, unc_method)\n",
    "\n",
    "    return tpr, fpr\n",
    "\n",
    "\n",
    "aucs_test = {'predictive-entropy': {'ensemble_dropout': []}}        # for ensemble, isStandard=False, unc=get_uncertainty(y_preds, unc_method).flatten()\n",
    "key = \"test\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        tpr, fpr = roc_plot_and_auroc(method, key, unc_name)\n",
    "        r = 6\n",
    "        print(f'{key} AUC: {np.round(auc(tpr, fpr), r) * 100}')\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "\n",
    "key = \"lockbox\"\n",
    "print(key)\n",
    "for unc_name, methods_dict in aucs_test.items():\n",
    "    print(unc_name)\n",
    "    for method, auc_lst in methods_dict.items():\n",
    "        tpr, fpr = roc_plot_and_auroc(method, key, unc_name)\n",
    "        r = 6\n",
    "        print(f'{key} AUC: {np.round(auc(tpr, fpr), r) * 100}')\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = load_dict_from_hdf5('predictions/predictions_duq.h5')\n",
    "data = methods['duq']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (9, 576, 4)\n",
      "data shape: (9, 576, 4)\n",
      "0 (576,)\n",
      "1 (576,)\n",
      "2 (576,)\n",
      "3 (576,)\n",
      "4 (576,)\n",
      "5 (576,)\n",
      "6 (576,)\n",
      "7 (576,)\n",
      "8 (576,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 576, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isStandard = True   # Because DUQ is only 1 forward pass\n",
    "\n",
    "acc = []\n",
    "print(f'data shape: {data[\"preds\"].shape}')\n",
    "data = avg_forward_passes(data) if not isStandard else data\n",
    "print(f'data shape: {data[\"preds\"].shape}')\n",
    "y_preds = data[\"preds\"].argmax(axis=-1)\n",
    "y_trues = data[\"labels\"].argmax(axis=-1)\n",
    "\n",
    "# Get accuracy of each subject\n",
    "for idx, subject in enumerate(y_trues):\n",
    "    print(idx, subject.shape)\n",
    "    score = accuracy_score(y_pred=subject, y_true=y_preds[idx], normalize=True)\n",
    "    acc.append(score)\n",
    "\n",
    "data['labels'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-subject AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per-subject uncertainties and AUROC\n",
    "This is exactly what I need:\n",
    "    - Per subject AUROC. This can only be done with array of shape (9, 576).\n",
    "        - start w/ (50, 9, 50, 576, 4) for a method.\n",
    "        - Mean axis=0 -> (9, 50, 576, 4)\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "        - For each subject in axis 0, calculate AUROC to get final array of (9, 1)\n",
    "    - Array of shape (9, 1) for uncertanties\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (50, 576, 4)\n",
    "'''\n",
    "def get_fpr_tpr(y_true, y_pred, isStandard):\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    y_pred = y_pred if isStandard else y_pred.mean(axis=-3)\n",
    "    y_true = get_in_shape(y_true)\n",
    "    y_pred = get_in_shape(y_pred) if isStandard else get_in_shape(y_pred.mean(axis=-3))\n",
    "\n",
    "    \n",
    "    # print(f'y_true: {y_true.shape}, y_pred: {y_pred.shape}, certains: {unc.shape}')\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "        uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "def get_auroc(y_true, y_pred, unc, isStandard):\n",
    "    tpr, fpr = get_fpr_tpr(y_true, y_pred, unc, isStandard)\n",
    "    return auc(tpr, fpr)\n",
    "\n",
    "def per_subject_metrics(data, isStandard, key, unc_method):\n",
    "    key_set = data[key]        # Whether lockbox or preds of the method\n",
    "    y_true = key_set['labels']\n",
    "    y_preds = key_set['preds'].mean(axis=0)     # CHANGE: FIRST AXIS IS NOT ALWAYS 50! FOR METHODS WITHOUT 50 SETS IT'S SIMPLY 9!\n",
    "    unc = get_uncertainty(y_preds, unc_method, isStandard)\n",
    "    per_subject_aucs = []\n",
    "    # print(y_preds.shape)\n",
    "    for subject_id in range(y_preds.shape[0]):\n",
    "        per_subject_aucs.append(get_auroc(y_true[subject_id], y_preds[subject_id], unc[subject_id], isStandard))\n",
    "\n",
    "    \n",
    "    return np.array(per_subject_aucs), unc.mean(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "data: (50, 9, 50, 576, 4)\n",
    "method: 'mcdropconnect'/'mcdropout'/'standard'/'standard_dropconnect'\n",
    "key: 'test'/'lockbox'\n",
    "'''\n",
    "def do_everything(data, method, key, unc_method):\n",
    "    # data shape for UQ preds: (50, 9, 50, 576, 4)\n",
    "    isStandard = checkIfStandard(method)\n",
    "    aurocs, uncertainties = per_subject_metrics(data, isStandard, key, unc_method)\n",
    "    return aurocs, uncertainties\n",
    "\n",
    "\n",
    "def load_predictions_TEST(method, num=None):\n",
    "    if 'standard' in method:        # Like standard_dropout/standard/standard_dropconnect\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_standard.h5')\n",
    "    elif 'ensemble' in method:      # currently only ensemble based on regular dropout\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_ensemble_dropout.h5')\n",
    "    elif 'duq' in method:\n",
    "        return load_dict_from_hdf5(f'predictions/predictions_duq.h5')\n",
    "    elif 'flipout' in method:\n",
    "        return load_dict_from_hdf5(f'predictions/flipout/predictions_flipout_{num}.h5')\n",
    "    elif num != None:                           # Only cases are MC-Dropout and MC-DropConnect\n",
    "        if 'standard' in method:\n",
    "           return load_dict_from_hdf5(f'predictions/predictions_{num}.h5')\n",
    "        else:   # Only flipout satisfies this condition for now\n",
    "           return load_dict_from_hdf5(f'predictions/flipout/predictions_flipout_{num}.h5')\n",
    "    else:\n",
    "      num = np.max(glob.glob('\\d+(?=\\.)')) + 1   # Trying to get number of preds for mcdropout and mcdropconnect\n",
    "      ret = {method: {'test': {'preds':[], 'labels':[]}, 'lockbox': {'preds':[], 'labels':[]}}}\n",
    "      for n in range(num):\n",
    "          temp_holder = load_dict_from_hdf5(f'predictions/predictions_{n}.hdf5')\n",
    "          ret[method]['test']['preds'].append(temp_holder[method]['test']['preds'])\n",
    "          ret[method]['lockbox']['preds'].append(temp_holder[method]['lockbox']['preds'])\n",
    "          if n == 0:\n",
    "            ret[method]['test']['labels'].append(temp_holder[method]['test']['labels'])\n",
    "            ret[method]['lockbox']['labels'].append(temp_holder[method]['lockbox']['labels'])\n",
    "\n",
    "      ret[method]['test']['preds'] = np.array(ret[method]['test']['preds'])\n",
    "      ret[method]['lockbox']['preds'] = np.array(ret[method]['lockbox']['preds'])\n",
    "      return ret\n",
    "\n",
    "\n",
    "\n",
    "dicts = {'mcdropconnect':{'aucs': \n",
    "                          {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'mcdropout':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'standard':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'standard_dropconnect':{'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'ensemble': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'duq': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}, \n",
    "        'flipout': {'aucs': {'predictive-entropy': [],\n",
    "                           'mutual-information': [],\n",
    "                           'shannon-entropy': []}}}\n",
    "unc_methods = ['predictive-entropy', 'mutual-information', 'shannon-entropy']\n",
    "key = \"test\"\n",
    "for method, values in dicts.items():\n",
    "    data = load_predictions_TEST(method)\n",
    "    for unc in unc_methods:\n",
    "        aurocs, _ = do_everything(values, method, key)\n",
    "        # Normalizes AREA UNDER CURVE to sum up to 1. y-axis values are meaningless.\n",
    "        print(method)\n",
    "        r = 6\n",
    "        values['aucs'][unc] = aurocs\n",
    "        # print(f'{key} set avg AUROC: {np.mean(aucs)} +/- {np.std(aucs)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
